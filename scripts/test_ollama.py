"""
test_ollama.py
Script de prueba para verificar que Ollama genera texto correctamente.
"""

import sys
import time
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from llm.ollama_client import generate_text

print("=" * 60)
print("ğŸ§ª PRUEBA DE OLLAMA")
print("=" * 60)

# Prompt simple para prueba
prompt = """Genera una frase corta y simple sobre tecnologÃ­a, mÃ¡ximo 20 palabras. 
No uses formato markdown ni asteriscos. Habla directamente.

Comienza:"""

print(f"\nğŸ“ Prompt de prueba: {prompt[:100]}...")
print("\nğŸ¤– Generando texto con Ollama (llama2)...")
print("â±ï¸  Esto puede tardar 1-3 minutos en la primera ejecuciÃ³n...")
print("    (Las siguientes serÃ¡n mÃ¡s rÃ¡pidas)\n")

# Medir tiempo
inicio = time.time()

# Generar texto
texto = generate_text("llama2", prompt, timeout=180)

fin = time.time()
tiempo_total = fin - inicio

print("\n" + "=" * 60)
print("ğŸ“Š RESULTADOS")
print("=" * 60)
print(f"â±ï¸  Tiempo de generaciÃ³n: {tiempo_total:.2f} segundos")
print(f"ğŸ“ Texto generado ({len(texto)} caracteres):")
print("-" * 60)
print(texto)
print("-" * 60)

if tiempo_total > 180:
    print("\nâŒ PROBLEMA: GeneraciÃ³n superÃ³ el timeout")
    print("ğŸ’¡ SoluciÃ³n: Usa un modelo mÃ¡s rÃ¡pido como 'tinyllama'")
elif tiempo_total > 60:
    print("\nâš ï¸  ADVERTENCIA: GeneraciÃ³n lenta")
    print(f"   TomÃ³ {tiempo_total:.0f} segundos (mÃ¡s de 1 minuto)")
    print("ğŸ’¡ Considera usar un modelo mÃ¡s rÃ¡pido")
else:
    print(f"\nâœ… Ã‰XITO: GeneraciÃ³n completada en {tiempo_total:.0f} segundos")

print("=" * 60)
