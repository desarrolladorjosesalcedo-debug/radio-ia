"""
radio_loop.py
Motor principal de Radio IA - El "cerebro" del proyecto.

Este m√≥dulo coordina todo el flujo de la radio:
1. Selecciona un tema aleatorio
2. Construye el prompt din√°mico
3. Genera texto con Ollama LLM
4. Convierte el texto a voz con Piper TTS
5. Reproduce el audio
6. Repite el proceso infinitamente

Es el componente central que orquesta todos los dem√°s m√≥dulos para
crear una transmisi√≥n de radio continua y autom√°tica.

Uso:
    start_radio()  # Inicia la radio (loop infinito)
"""

import time
import logging
import sys
import yaml
import threading
from pathlib import Path
from typing import Optional, Tuple

# Importar m√≥dulos del proyecto
from core.topics import get_random_topic
from core.prompt import build_prompt, build_intro_prompt
from core.session_history import SessionHistory
from core.active_session import ActiveSessionManager, build_anti_repetition_context
from tts.tts_manager import get_tts_manager
from llm.ollama_client import generate_text, check_ollama_available
from llm.groq_client import generate_text_groq, check_groq_available
from tts.piper_tts import synthesize_speech, check_piper_available, validate_model
from tts.edge_tts_client import synthesize_speech_edge, check_edge_tts_available
from tts.gtts_client import synthesize_speech_gtts, check_gtts_available
from utils.audio_player import play_audio, check_ffplay_available
from utils.audio_output import output_audio

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ========== FLAGS DE CONTROL GLOBAL ==========
# Estos flags permiten pausar/detener la radio desde threads externos (API web)
_stop_flag = None
_pause_flag = None


# Configuraci√≥n por defecto
DEFAULT_CONFIG = {
    "provider": "groq",  # "groq" o "ollama"
    "model_name": "llama2-70b-4096",  # Modelo
    "model_path": "models/piper/es_ES-davefx-medium.onnx",  # Modelo de Piper
    "duration_seconds": 20,  # Duraci√≥n de cada segmento
    "delay_seconds": 1.0,  # Pausa entre segmentos
    "sample_rate": 22050,  # Frecuencia de audio
    "max_retries": 3,  # Reintentos en caso de error
    "api_key": "",  # API key para Groq
    "max_tokens": 500  # M√°ximo de tokens
}


def load_config() -> dict:
    """
    Carga la configuraci√≥n desde settings.yaml.
    Si no existe, usa la configuraci√≥n por defecto.
    
    Returns:
        dict: Diccionario con la configuraci√≥n
    """
    settings_path = Path(__file__).parent.parent.parent / "config" / "settings.yaml"
    
    if not settings_path.exists():
        logger.warning(f"‚ö†Ô∏è  No se encontr√≥ {settings_path}, usando configuraci√≥n por defecto")
        return DEFAULT_CONFIG.copy()
    
    try:
        with open(settings_path, 'r', encoding='utf-8') as f:
            settings = yaml.safe_load(f)
        
        # Mapear configuraci√≥n de YAML a formato interno
        config = {
            "provider": settings.get("llm", {}).get("provider", DEFAULT_CONFIG["provider"]),
            "model_name": settings.get("llm", {}).get("model_name", DEFAULT_CONFIG["model_name"]),
            "model_path": settings.get("tts", {}).get("model_path", DEFAULT_CONFIG["model_path"]),
            "duration_seconds": settings.get("radio", {}).get("duration_seconds", DEFAULT_CONFIG["duration_seconds"]),
            "delay_seconds": settings.get("radio", {}).get("delay_seconds", DEFAULT_CONFIG["delay_seconds"]),
            "sample_rate": settings.get("audio", {}).get("sample_rate", DEFAULT_CONFIG["sample_rate"]),
            "max_retries": settings.get("radio", {}).get("max_retries", DEFAULT_CONFIG["max_retries"]),
            "skip_intro": settings.get("radio", {}).get("skip_intro", False),
            "mode": settings.get("radio", {}).get("mode", "topics"),
            "monologue_theme": settings.get("radio", {}).get("monologue_theme", "inteligencia artificial"),
            "reader_file": settings.get("radio", {}).get("reader_file", "input/texto.txt"),
            "tts_speaker_id": settings.get("tts", {}).get("speaker_id"),
            "tts_length_scale": settings.get("tts", {}).get("length_scale", 1.0),
            "edge_voice": settings.get("tts", {}).get("edge_voice", "es-CO-SalomeNeural"),
            "llm_timeout": settings.get("llm", {}).get("timeout", 30),
            "api_key": settings.get("llm", {}).get("api_key", ""),
            "max_tokens": settings.get("llm", {}).get("max_tokens", 500),
            "history_dir": settings.get("history", {}).get("dir", "history"),
            "continue_session": settings.get("history", {}).get("continue_session", True),
            "session_timeout_hours": settings.get("history", {}).get("session_timeout_hours", 24),
            "max_content_memory": settings.get("history", {}).get("max_content_memory", 5),
        }
        
        logger.info(f"‚úÖ Configuraci√≥n cargada desde {settings_path}")
        return config
    
    except Exception as e:
        logger.error(f"‚ùå Error leyendo configuraci√≥n: {e}")
        logger.info("üìã Usando configuraci√≥n por defecto")
        return DEFAULT_CONFIG.copy()


def check_dependencies(config: dict) -> bool:
    """
    Verifica que todas las dependencias necesarias est√©n instaladas.
    
    Args:
        config (dict): Configuraci√≥n con provider y api_key
    
    Returns:
        bool: True si todas las dependencias est√°n disponibles
    """
    logger.info("üîç Verificando dependencias...")
    
    all_available = True
    provider = config.get("provider", "ollama")
    
    # Verificar LLM seg√∫n provider
    if provider == "groq":
        api_key = config.get("api_key", "")
        if not api_key:
            logger.error("‚ùå Falta API key de Groq")
            logger.info("üí° Configura api_key en settings.yaml")
            all_available = False
        elif not check_groq_available(api_key):
            logger.error("‚ùå Groq API no est√° disponible")
            all_available = False
        else:
            logger.info("‚úÖ Groq API disponible")
    else:  # ollama
        if not check_ollama_available():
            logger.error("‚ùå Ollama no est√° disponible")
            logger.info("üí° Instala Ollama desde: https://ollama.ai/")
            all_available = False
    
    # Verificar Piper
    if not check_piper_available():
        logger.error("‚ùå Piper TTS no est√° disponible")
        logger.info("üí° Instala Piper desde: https://github.com/rhasspy/piper")
        all_available = False
    
    # Verificar ffplay
    if not check_ffplay_available():
        logger.error("‚ùå ffplay no est√° disponible")
        logger.info("üí° Instala FFmpeg desde: https://ffmpeg.org/")
        all_available = False
    
    if all_available:
        logger.info("‚úÖ Todas las dependencias est√°n disponibles")
    
    return all_available


def generate_segment(
    model_name: str,
    model_path: str,
    duration_seconds: int = 20,
    topic: Optional[str] = None,
    provider: str = "groq",
    api_key: str = "",
    max_tokens: int = 500,
    llm_timeout: int = 30,
    edge_voice: str = "es-CO-SalomeNeural",
    mode: str = "topics",
    previous_content: Optional[str] = None,
    reader_text: Optional[str] = None,
    anti_repetition_context: str = ""
) -> tuple[str, bytes, str, str]:
    """
    Genera un segmento completo de radio (texto + audio).
    
    Args:
        model_name (str): Nombre del modelo de Ollama
        model_path (str): Ruta al modelo de Piper
        duration_seconds (int): Duraci√≥n aproximada del segmento
        topic (Optional[str]): Tema espec√≠fico, o None para aleatorio
        mode (str): "topics", "monologue", o "reader"
        previous_content (Optional[str]): Contenido previo para modo mon√≥logo
        reader_text (Optional[str]): Texto a leer en modo reader
        anti_repetition_context (str): Contexto de anti-repetici√≥n para evitar contenido ya cubierto
    
    Returns:
        tuple[str, bytes, str, str]: (texto_generado, audio_bytes, topic, tts_provider)
    """
    # Importar build_monologue_prompt
    from core.prompt import build_monologue_prompt
    
    # Paso 1: Elegir tema o usar tema de mon√≥logo
    if topic is None:
        topic = get_random_topic()
    logger.info(f"üéØ Tema seleccionado: '{topic}'")
    
    # Paso 2: Obtener texto seg√∫n modo
    if mode == "reader":
        # Modo lector: usar texto proporcionado directamente
        if not reader_text:
            logger.error("‚ùå Modo reader pero no hay texto para leer")
            return "", b"", "Sin texto", "none"
        texto = reader_text
        logger.info(f"üìñ Usando texto del lector ({len(texto)} caracteres)")
    else:
        # Modos topics y monologue: generar con LLM
        # Paso 2: Construir prompt seg√∫n modo
        if mode == "monologue":
            prompt = build_monologue_prompt(
                topic, 
                previous_content=previous_content, 
                duration_seconds=duration_seconds,
                anti_repetition_context=anti_repetition_context
            )
            logger.info("üß† Prompt de mon√≥logo construido")
        else:
            prompt = build_prompt(topic, duration_seconds=duration_seconds)
            logger.info("üìù Prompt construido")
        
        # Paso 3: Generar texto con LLM (Groq u Ollama)
        logger.info(f"ü§ñ Generando texto con {provider.upper()}...")
        
        if provider == "groq":
            texto = generate_text_groq(model_name, prompt, api_key, max_tokens=max_tokens)
        else:  # ollama
            texto = generate_text(model_name, prompt, timeout=llm_timeout)
    
    if not texto or len(texto.strip()) < 10:
        logger.warning("‚ö†Ô∏è  Texto generado inv√°lido o vac√≠o")
        return "", b"", topic, "none"
    
    logger.info(f"‚úÖ Texto generado ({len(texto)} caracteres)")
    
    # Paso 4: Convertir texto a voz (Piper ‚Üí Edge TTS ‚Üí Google TTS)
    logger.info("üé§ Sintetizando voz...")
    audio = synthesize_speech(texto, model_path, length_scale=duration_seconds/20.0)
    tts_provider = "piper"
    
    # Si Piper falla, intentar con Edge TTS (mejor calidad)
    if not audio or len(audio) < 100:
        logger.warning("‚ö†Ô∏è  Piper fall√≥, intentando con Edge TTS...")
        audio = synthesize_speech_edge(texto, voice=edge_voice)
        tts_provider = "edge"
    
    # Si Edge TTS falla, usar Google TTS como √∫ltimo recurso
    if not audio or len(audio) < 100:
        logger.warning("‚ö†Ô∏è  Edge TTS fall√≥, usando Google TTS...")
        audio = synthesize_speech_gtts(texto)
        tts_provider = "gtts"
    
    if not audio or len(audio) < 100:
        logger.warning("‚ö†Ô∏è  Audio generado inv√°lido o vac√≠o")
        return texto, b"", topic, "none"
    
    logger.info(f"‚úÖ Audio sintetizado ({len(audio)} bytes)")
    
    return texto, audio, topic, tts_provider


def play_intro(model_name: str, model_path: str, provider: str = "groq", api_key: str = "", max_tokens: int = 200, edge_voice: str = "es-CO-SalomeNeural") -> Optional[str]:
    """
    Reproduce una introducci√≥n de bienvenida a la radio.
    
    Args:
        model_name (str): Nombre del modelo de Ollama
        model_path (str): Ruta al modelo de Piper
    
    Returns:
        Optional[str]: Texto de la introducci√≥n generada, o None si falla
    """
    logger.info("üéôÔ∏è  Generando introducci√≥n de Radio IA...")
    
    try:
        intro_prompt = build_intro_prompt()
        
        if provider == "groq":
            intro_text = generate_text_groq(model_name, intro_prompt, api_key, max_tokens=max_tokens)
        else:
            intro_text = generate_text(model_name, intro_prompt)
        
        if intro_text:
            intro_audio = synthesize_speech(intro_text, model_path)
            # Si Piper falla, intentar con Edge TTS
            if not intro_audio or len(intro_audio) < 100:
                logger.warning("‚ö†Ô∏è  Piper fall√≥, usando Edge TTS para intro...")
                intro_audio = synthesize_speech_edge(intro_text, voice=edge_voice)
            # Si Edge TTS falla, usar Google TTS
            if not intro_audio or len(intro_audio) < 100:
                logger.warning("‚ö†Ô∏è  Edge TTS fall√≥, usando Google TTS para intro...")
                intro_audio = synthesize_speech_gtts(intro_text)
            
            if intro_audio:
                play_audio(intro_audio)
                logger.info("‚úÖ Introducci√≥n reproducida")
                return intro_text
        
        logger.warning("‚ö†Ô∏è  No se pudo generar la introducci√≥n")
        return None
    except Exception as e:
        logger.error(f"‚ùå Error generando introducci√≥n: {e}")
        return None


def start_radio(
    delay_seconds: float = 1.0,
    max_iterations: Optional[int] = None,
    skip_intro: bool = False,
    stop_flag: Optional[threading.Event] = None,
    pause_flag: Optional[threading.Event] = None
) -> None:
    """
    Inicia el bucle principal de Radio IA.
    
    Esta funci√≥n ejecuta un ciclo infinito que:
    - Selecciona temas aleatorios
    - Genera contenido con IA
    - Sintetiza voz
    - Reproduce audio continuamente
    
    Args:
        delay_seconds (float): Pausa entre segmentos en segundos (default: 1.0)
        max_iterations (Optional[int]): N√∫mero m√°ximo de iteraciones (None = infinito)
        skip_intro (bool): Si True, omite la introducci√≥n (default: False)
        stop_flag (Optional[threading.Event]): Flag para detener la radio externamente
        pause_flag (Optional[threading.Event]): Flag para pausar la radio externamente
    
    Raises:
        KeyboardInterrupt: Cuando el usuario presiona Ctrl+C
    """
    global _stop_flag, _pause_flag
    
    # Guardar referencias a los flags para acceso global
    _stop_flag = stop_flag
    _pause_flag = pause_flag
    logger.info("=" * 60)
    logger.info("üéôÔ∏è  RADIO IA - INICIANDO TRANSMISI√ìN")
    logger.info("=" * 60)
    
    # Cargar configuraci√≥n
    config = load_config()
    
    # Verificar dependencias
    if not check_dependencies(config):
        logger.error("‚ùå No se puede iniciar la radio sin las dependencias necesarias")
        logger.info("üí° Instala las herramientas requeridas y vuelve a intentar")
        return
    
    provider = config["provider"]
    model_name = config["model_name"]
    model_path = config["model_path"]
    duration_seconds = config["duration_seconds"]
    sample_rate = config["sample_rate"]
    max_retries = config["max_retries"]
    api_key = config.get("api_key", "")
    max_tokens = config.get("max_tokens", 500)
    mode = config.get("mode", "topics")
    monologue_theme = config.get("monologue_theme", "inteligencia artificial")
    
    # Validar modelo de Piper
    if not Path(model_path).exists():
        logger.error(f"‚ùå Modelo de Piper no encontrado: {model_path}")
        logger.info("üí° Descarga un modelo de voz y col√≥calo en models/piper/")
        logger.info("   Modelos disponibles en: https://github.com/rhasspy/piper/releases")
        return
    
    # Cargar segmentos en modo reader
    reader_segments = None
    reader_file = None
    if mode == "reader":
        from core.text_reader import load_and_split_text, validate_text_file
        reader_file = config.get("reader_file", "input/texto.txt")
        
        if not validate_text_file(reader_file):
            logger.error(f"‚ùå Archivo de texto inv√°lido: {reader_file}")
            logger.info("üí° Crea el archivo input/texto.txt con el contenido a leer")
            return
        
        reader_segments = load_and_split_text(reader_file, duration_seconds)
        if not reader_segments:
            logger.error("‚ùå No se pudo procesar el archivo de texto")
            return
        
        logger.info(f"üìñ Texto cargado: {len(reader_segments)} segmentos")
    
    logger.info(f"üåê Proveedor LLM: {provider.upper()}")
    logger.info(f"ü§ñ Modelo LLM: {model_name}")
    logger.info(f"üé§ Modelo TTS: {model_path}")
    logger.info(f"üé≠ Modo: {mode.upper()}")
    if mode == "monologue":
        logger.info(f"üß† Tema del mon√≥logo: {monologue_theme}")
    elif mode == "reader":
        logger.info(f"üìñ Archivo: {reader_file}")
        logger.info(f"üìñ Segmentos: {len(reader_segments)}")
    logger.info(f"‚è±Ô∏è  Duraci√≥n por segmento: {duration_seconds}s")
    logger.info(f"üîä Sample rate: {sample_rate} Hz")
    logger.info("=" * 60)
    
    # Inicializar historial de sesi√≥n
    history_dir = config.get("history_dir", "history")
    session_history = SessionHistory(history_dir)
    session_id = session_history.start_session()
    logger.info(f"üìù Sesi√≥n iniciada: {session_id}")
    
    # Inicializar gesti√≥n de sesi√≥n activa (anti-repetici√≥n)
    active_session_manager = ActiveSessionManager(
        history_dir=history_dir,
        timeout_hours=config.get("session_timeout_hours", 24)
    )
    
    # Obtener o crear sesi√≥n activa
    active_session_id, is_continuing, previous_session_content = active_session_manager.get_or_create_session()
    
    if config.get("continue_session", True) and is_continuing and mode == "monologue":
        logger.info(f"‚ôªÔ∏è  Continuando sesi√≥n activa: {active_session_id}")
        logger.info(f"üìö Contenido previo detectado: {len(previous_session_content)} caracteres")
        anti_repetition_context = build_anti_repetition_context(previous_session_content)
        logger.info(f"üö´ Contexto anti-repetici√≥n activado")
    else:
        if not is_continuing:
            logger.info(f"üÜï Nueva sesi√≥n activa: {active_session_id}")
        else:
            logger.info(f"üìù Sesi√≥n {active_session_id} (modo {mode} - sin anti-repetici√≥n)")
        anti_repetition_context = ""
    
    logger.info("=" * 60)
    
    # Reproducir introducci√≥n
    if not skip_intro:
        intro_text = play_intro(model_name, model_path, provider=provider, api_key=api_key, max_tokens=200, edge_voice=config.get("edge_voice", "es-CO-SalomeNeural"))
        if intro_text:
            session_history.add_intro(intro_text, config.get("edge_voice", "es-CO-SalomeNeural"), 15.0)
        time.sleep(delay_seconds)
    
    # Iniciar bucle principal
    logger.info("üîÑ Iniciando bucle de transmisi√≥n continua...")
    logger.info("‚å®Ô∏è  Presiona Ctrl+C para detener la transmisi√≥n")
    logger.info("=" * 60)
    
    iteration = 0
    consecutive_errors = 0
    previous_content = None  # Para modo mon√≥logo
    
    # Variables para generaci√≥n en paralelo
    next_segment = None  # (texto, audio, topic, tts_provider)
    generation_thread = None
    
    def generate_next_segment(prev_content=None, segment_index=None, anti_rep_context=""):
        """Genera el siguiente segmento en segundo plano"""
        # En modo mon√≥logo, siempre usar el tema configurado
        segment_topic = monologue_theme if mode == "monologue" else None
        
        # En modo reader, obtener el texto del segmento
        segment_text = None
        if mode == "reader" and segment_index is not None and reader_segments:
            if segment_index < len(reader_segments):
                segment_text = reader_segments[segment_index]
        
        return generate_segment(
            model_name=model_name,
            model_path=model_path,
            duration_seconds=duration_seconds,
            topic=segment_topic,
            provider=provider,
            api_key=api_key,
            max_tokens=max_tokens,
            llm_timeout=config.get("llm_timeout", 30),
            edge_voice=config.get("edge_voice", "es-CO-SalomeNeural"),
            mode=mode,
            previous_content=prev_content,
            reader_text=segment_text,
            anti_repetition_context=anti_rep_context
        )
    
    while True:
        try:
            # Verificar flag de detenci√≥n
            if stop_flag and stop_flag.is_set():
                logger.info("üõë Se√±al de detenci√≥n recibida")
                break
            
            # Verificar flag de pausa
            if pause_flag:
                while pause_flag.is_set():
                    logger.info("‚è∏Ô∏è  Radio en pausa...")
                    time.sleep(0.5)
                    # Tambi√©n verificar stop durante la pausa
                    if stop_flag and stop_flag.is_set():
                        logger.info("üõë Se√±al de detenci√≥n recibida durante pausa")
                        break
                if stop_flag and stop_flag.is_set():
                    break
                logger.info("‚ñ∂Ô∏è  Radio reanudada")
            
            iteration += 1
            
            # Verificar si se alcanz√≥ el m√°ximo de iteraciones
            if max_iterations is not None and iteration > max_iterations:
                logger.info(f"‚úÖ Alcanzado el m√°ximo de iteraciones: {max_iterations}")
                break
            
            logger.info(f"\n{'=' * 60}")
            logger.info(f"üìª SEGMENTO #{iteration}")
            logger.info(f"{'=' * 60}")
            
            # Si hay un segmento pre-generado, usarlo
            if next_segment is not None and generation_thread is not None:
                logger.info("‚ö° Usando segmento pre-generado (sin espera)")
                generation_thread.join()  # Esperar a que termine si a√∫n no lo hizo
                texto, audio, topic, tts_provider = next_segment
                next_segment = None
            else:
                # Primera iteraci√≥n: generar normalmente
                # En modo mon√≥logo, siempre usar el tema configurado
                segment_topic = monologue_theme if mode == "monologue" else None
                
                # En modo reader, obtener el texto del segmento
                segment_text = None
                if mode == "reader" and reader_segments:
                    if iteration - 1 < len(reader_segments):
                        segment_text = reader_segments[iteration - 1]
                    else:
                        logger.info("‚úÖ Todos los segmentos del texto han sido le√≠dos")
                        break
                
                texto, audio, topic, tts_provider = generate_segment(
                    model_name=model_name,
                    model_path=model_path,
                    duration_seconds=duration_seconds,
                    topic=segment_topic,
                    provider=provider,
                    api_key=api_key,
                    max_tokens=max_tokens,
                    llm_timeout=config.get("llm_timeout", 30),
                    edge_voice=config.get("edge_voice", "es-CO-SalomeNeural"),
                    mode=mode,
                    previous_content=previous_content,
                    reader_text=segment_text,
                    anti_repetition_context=anti_repetition_context
                )
            
            # Validar que se gener√≥ contenido
            if not texto:
                logger.warning("‚ö†Ô∏è  No se pudo generar texto. Reintentando...")
                consecutive_errors += 1
                
                if consecutive_errors >= max_retries:
                    logger.error(f"‚ùå Demasiados errores consecutivos ({max_retries}). Deteniendo.")
                    break
                
                time.sleep(delay_seconds * 2)
                continue
            
            if not audio:
                logger.warning("‚ö†Ô∏è  No se pudo generar audio. Reintentando...")
                consecutive_errors += 1
                
                if consecutive_errors >= max_retries:
                    logger.error(f"‚ùå Demasiados errores consecutivos ({max_retries}). Deteniendo.")
                    break
                
                time.sleep(delay_seconds * 2)
                continue
            
            # Resetear contador de errores si todo sali√≥ bien
            consecutive_errors = 0
            
            # INICIAR GENERACI√ìN DEL SIGUIENTE SEGMENTO EN PARALELO
            # Mientras se reproduce el actual, generar el siguiente
            should_generate_next = True
            
            # No generar siguiente si hay se√±al de detenci√≥n
            if stop_flag and stop_flag.is_set():
                should_generate_next = False
            elif mode == "reader" and reader_segments:
                # En modo reader, verificar si hay m√°s segmentos
                should_generate_next = iteration < len(reader_segments)
            elif max_iterations is not None:
                should_generate_next = iteration < max_iterations
            
            if should_generate_next:
                logger.info("üîÑ Generando siguiente segmento en segundo plano...")
                
                def generate_and_store():
                    nonlocal next_segment
                    try:
                        # Pasar contenido previo solo en modo mon√≥logo
                        prev = previous_content if mode == "monologue" else None
                        # En modo reader, pasar el √≠ndice del siguiente segmento
                        seg_idx = iteration if mode == "reader" else None
                        # Pasar contexto anti-repetici√≥n solo en modo mon√≥logo
                        anti_rep = anti_repetition_context if mode == "monologue" else ""
                        next_segment = generate_next_segment(prev_content=prev, segment_index=seg_idx, anti_rep_context=anti_rep)
                    except Exception as e:
                        logger.error(f"‚ùå Error generando siguiente segmento: {e}")
                        next_segment = None
                
                generation_thread = threading.Thread(target=generate_and_store, daemon=True)
                generation_thread.start()
            
            # Reproducir audio (local o streaming seg√∫n configuraci√≥n)
            logger.info("üîä Reproduciendo segmento...")
            output_audio(
                audio, 
                sample_rate=sample_rate,
                metadata={
                    "topic": topic,
                    "text": texto,
                    "duration": duration_seconds,
                    "provider": tts_provider
                }
            )
            
            # Guardar segmento en historial
            session_history.add_segment(
                topic=topic,
                text=texto,
                voice=config.get("edge_voice", "es-CO-SalomeNeural"),
                duration=duration_seconds,
                tts_provider=tts_provider
            )
            
            # Actualizar contenido previo para modo mon√≥logo
            if mode == "monologue":
                previous_content = texto
                # Agregar contenido a sesi√≥n activa para anti-repetici√≥n
                active_session_manager.add_content(active_session_id, texto, config.get("max_content_memory", 5))
            
            logger.info(f"‚úÖ Segmento #{iteration} completado exitosamente")
            
            # Pausa m√≠nima (el siguiente segmento ya deber√≠a estar listo)
            if delay_seconds > 0:
                if generation_thread and generation_thread.is_alive():
                    logger.info(f"‚è≥ Esperando que termine generaci√≥n del siguiente segmento...")
                else:
                    logger.info(f"‚ö° Siguiente segmento ya listo - sin pausa")
                time.sleep(delay_seconds)
        
        except KeyboardInterrupt:
            logger.info("\n" + "=" * 60)
            logger.info("‚èπÔ∏è  Interrupci√≥n recibida (Ctrl+C)")
            logger.info("üéôÔ∏è  Deteniendo Radio IA...")
            session_history.end_session()
            logger.info(f"üíæ Sesi√≥n guardada: {session_id}")
            logger.info("=" * 60)
            break
        
        except Exception as e:
            logger.error(f"‚ùå Error inesperado en el ciclo de radio: {e}")
            consecutive_errors += 1
            
            if consecutive_errors >= max_retries:
                logger.error(f"‚ùå Demasiados errores consecutivos ({max_retries}). Deteniendo.")
                break
            
            logger.info("‚è∏Ô∏è  Esperando 2 segundos antes de reintentar...")
            time.sleep(2)
    
    # Asegurar que se guarde la sesi√≥n al finalizar
    session_history.end_session()
    
    logger.info("\n" + "=" * 60)
    logger.info(f"üìä ESTAD√çSTICAS FINALES")
    logger.info(f"   Sesi√≥n ID: {session_id}")
    logger.info(f"   Segmentos generados: {iteration}")
    logger.info(f"   Errores consecutivos: {consecutive_errors}")
    logger.info("=" * 60)
    logger.info("üíæ Para ver el historial: python src/main.py --list-sessions")
    logger.info(f"üíæ Para reproducir esta sesi√≥n: python src/main.py --replay {session_id}")
    logger.info("=" * 60)
    logger.info("üëã Gracias por escuchar Radio IA")
    logger.info("=" * 60)


# Funci√≥n auxiliar para compatibilidad con main.py
def start_radio_loop(delay_seconds: float = 1.0):
    """
    Alias de start_radio() para compatibilidad con versiones anteriores.
    
    Args:
        delay_seconds (float): Pausa entre segmentos
    """
    start_radio(delay_seconds=delay_seconds)
